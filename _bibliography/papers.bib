---
---

@string{aps = {American Physical Society,}}


@article{qiu2024deep,
  abbr={bioRxiv}
  title={A deep profile of gene expression across 18 human cancers},
  author={Qiu, Wei and Dincer, Ayse B and Janizek, Joseph D and Celik, Safiye and Pittet, Mikael and Naxerova*, Kamila and Lee*, Su-In},
  journal={bioRxiv},
  year={2024},
  publisher={Cold Spring Harbor Laboratory Preprints}
  abstract={{Clinically and biologically valuable information may reside untapped in large cancer gene expression data sets. Deep unsupervised learning has the potential to extract this information with unprecedented efficacy but has thus far been hampered by a lack of biological interpretability and robustness. Here, we present DeepProfile, a comprehensive framework that addresses current challenges in applying unsupervised deep learning to gene expression profiles. We use DeepProfile to learn low-dimensional latent spaces for 18 human cancers from 50,211 transcriptomes. DeepProfile outperforms existing dimensionality reduction methods with respect to biological interpretability. Using DeepProfile interpretability methods, we show that genes that are universally important in defining the latent spaces across all cancer types control immune cell activation, while cancer type-specific genes and pathways define molecular disease subtypes. By linking DeepProfile latent variables to secondary tumor characteristics, we discover that tumor mutation burden is closely associated with the expression of cell cycle-related genes. DNA mismatch repair and MHC class II antigen presentation pathway expression, on the other hand, are consistently associated with patient survival. We validate these results through Kaplan-Meier analyses and nominate tumor-associated macrophages as an important source of survival-correlated MHC class II transcripts. Our results illustrate the power of unsupervised deep learning for discovery of novel cancer biology from existing gene expression data.}},
  html={https://www.biorxiv.org/content/10.1101/2024.03.17.585426v1},
  pdf={https://www.biorxiv.org/content/10.1101/2024.03.17.585426v1.full.pdf},
  selected={true}
}

@article{guo2024retrieval,
  abbr={JBI},
  title={Retrieval augmentation of large language models for lay language generation},
  author={Guo*, Yue and Qiu*, Wei and Leroy, Gondy and Wang, Sheng and Cohen, Trevor},
  journal={Journal of Biomedical Informatics},
  volume={149},
  pages={104580},
  year={2024},
  publisher={Elsevier}
  abstract={{The complex linguistic structures and specialized terminology of expert-authored content limit the accessibility of biomedical literature to the general public. Automated methods have the potential to render this literature more interpretable to readers with different educational backgrounds. Prior work has framed such lay language generation as a summarization or simplification task. However, adapting biomedical text for the lay public includes the additional and distinct task of background explanation: adding external content in the form of definitions, motivation, or examples to enhance comprehensibility. This task is especially challenging because the source document may not include the required background knowledge. Furthermore, background explanation capabilities have yet to be formally evaluated, and little is known about how best to enhance them. To address this problem, we introduce Retrieval-Augmented Lay Language (RALL) generation, which intuitively fits the need for external knowledge beyond that in expert-authored source documents. In addition, we introduce CELLS, the largest (63k pairs) and broadest-ranging (12 journals) parallel corpus for lay language generation. To evaluate RALL, we augmented state-of-the-art text generation models with information retrieval of either term definitions from the UMLS and Wikipedia, or embeddings of explanations from Wikipedia documents. Of these, embedding-based RALL models improved summary quality and simplicity while maintaining factual correctness, suggesting that Wikipedia is a helpful source for background explanation in this context. We also evaluated the ability of both an open-source Large Language Model (Llama 2) and a closed-source Large Language Model (GPT-4) in background explanation, with and without retrieval augmentation. Results indicate that these LLMs can generate simplified content, but that the summary quality is not ideal. Taken together, this work presents the first comprehensive study of background explanation for lay language generation, paving the path for disseminating scientific knowledge to a broader audience. Our code and data are publicly available at: https://github.com/LinguisticAnomalies/pls_retrieval.}},
  html={https://www.sciencedirect.com/science/article/pii/S1532046423003015},
  pdf={https://pdf.sciencedirectassets.com/272371/1-s2.0-S1532046423X00124/1-s2.0-S1532046423003015/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEGcaCXVzLWVhc3QtMSJIMEYCIQDw5%2F3BiG0JfYtShDU%2FxPi1kMwi6ZngKFauhPI98%2BZWPwIhAOnqjZUNPza%2FUcfzuXJ7mmw9xen5VFZtn70bJWNSc0V8KrMFCBAQBRoMMDU5MDAzNTQ2ODY1IgypWZqzv9qjXlX%2BAG8qkAU2XDKQqdlfjpzITGHz8dX4qNvgYYqR39q%2ByMVc7OJnNLbksVdNOLLsieB8R3yrAgOCvgXDghaUfxTSbwHxIqNAxIXAQ7ilKoEDvsdUJxUnLClDZIc7M03ME9TpWibPlgGI3LbuDfG0SWGgvxnzF3DZrL5q9eFhdU7ij93tYjoWfAbH9jZgncuAiJEmJUZJ4jJOK%2Bqtkn7JAJ6imzqgsu6RByzm8OCW%2FOQpueMfGJDRvXuPz5QW0C9OgDmCXF%2Fj0IhmNCqxgq6kd8nMsE67mS7ndGp16%2FKO5xF5E2Q6q21Kmp%2FhTzP97TvrzgKJX%2BoNeUZVnNsYNHyiWODrdEgMTaFlRUOr2P%2BmD%2BpUi12NDf3Sb8MXreaj0TzT6TDu8zE%2BeNKrxLbpwv39c2ileM9DV0lwRJvx6ATzLDysPYUMwmXKy7Ak1jWZ7nMMTd%2Bjwd5UjxB3sP6tJz5dtma2FBRxiYztWPigLuf41QdJf3fcfkMoLtbPtgLfs91d3G2cLBulnyyd5jZQV9CmEayoVK4n1OkCjL%2F%2FkS37gZkMp8o3MLK6HJ3BhyxQy%2FIsVPlWzo%2FEAUOroj%2Fa0dzMPgjqa1lbPVEnOKRKLgL%2BsHAorPrH8uJHv%2FUs6q1ZVq5JE9VbN4EWYbs2uu1rQCcgbmwsGmgaZaDY99CZuH4yfKYA8SLjQUdZu1tiKovtG4GAoBtkBYNVjRDQhAkA8mSeDCkNuCBCDbVcxUeaZ0rFxHw7UcOhrbAdqJfs2c%2BVEFhYI0KZVhbLvNkXbcHyu0kdvvNsSuJDjwjLGZDcam0zaTlN%2FdngUSjduDxEptbjOwmzrvh%2FoaZYWii8v6UzGaZquP7i%2FVcOS686ZdNQis79dc1VXzPo1zLNIzCx1MSzBjqwATItEkVg6a2dZgH%2B2T06RDz30u8HMCZ%2BoBllHdJoLFVI8qgijYUUvgBkRrKKQ4FT4T3melq%2FxuUc2ICwcA6PNAkQ30hEZs%2Fk2n7W0KfSQ1UUgnBOVscVd48EtoZ8SQdkNeHUTIbI99j71esY1CY6HehDXXbzhV%2BrfXLygvbqv5TlfPxyiLDn8atBvWww%2FGrWVR0Z4XoUoX93La1d6H3a9JG41L1XtADGIbxViiMfcTBj&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20240618T073924Z&X-Amz-SignedHeaders=host&X-Amz-Expires=299&X-Amz-Credential=ASIAQ3PHCVTYSOKGEAMC%2F20240618%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=00fa9b94e8b95b7c1829f7fa105b2df98b63eb0eeed44c23c3c5104d48796e2e&hash=3bfa8828c756898cc6684bc210d66819ab91d9a955cea9ccfb8a89ec8ad27cd7&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1532046423003015&tid=spdf-97b2617b-8f3f-45f8-86eb-6ae3b6c70ac7&sid=2c72563e8e2f3947d82b26d0c7685ffddd2egxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=1311565751590650535a&rr=8959a014c9b0c878&cc=us},
  selected={true}
}

@article{qiu2023explainable,
  abbr={Lancet HL}
  title={ExplaiNAble BioLogical Age (ENABL Age): an artificial intelligence framework for interpretable biological age},
  author={Qiu, Wei and Chen, Hugh and Kaeberlein, Matt and Lee, Su-In},
  journal={The Lancet Healthy Longevity},
  volume={4},
  number={12},
  pages={e711--e723},
  year={2023},
  publisher={Elsevier},
  abstract={{Background
Biological age is a measure of health that offers insights into ageing. The existing age clocks, although valuable, often trade off accuracy and interpretability. We introduce ExplaiNAble BioLogical Age (ENABL Age), a computational framework that combines machine-learning models with explainable artificial intelligence (XAI) methods to accurately estimate biological age with individualised explanations.
Methods
To construct the ENABL Age clock, we first predicted an age-related outcome (eg, all-cause or cause-specific mortality), and then rescaled these predictions to estimate biological age, using UK Biobank and National Health and Nutrition Examination Survey (NHANES) datasets. We adapted existing XAI methods to decompose individual ENABL Ages into contributing risk factors. For broad accessibility, we developed two versions: ENABL Age-L, based on blood tests, and ENABL Age-Q, based on questionnaire characteristics. Finally, we validated diverse ageing mechanisms captured by each ENABL Age clock through genome-wide association studies (GWAS) association analyses.
Findings
Our ENABL Age clock was significantly correlated with chronological age (r=0·7867, p<0·0001 for UK Biobank; r=0·7126, p<0·0001 for NHANES). These clocks distinguish individuals who are healthy (ie, their ENABL Age is lower than their chronological age) from those who are unhealthy (ie, their ENABL Age is higher than their chronological age), predicting mortality more effectively than existing clocks. Groups of individuals who were unhealthy showed approximately three to 12 times higher log hazard ratio than healthy groups, as per ENABL Age. The clocks achieved high mortality prediction power with an area under the receiver operating characteristic curve of 0·8179 for 5-year mortality and 0·8115 for 10-year mortality on the UK Biobank dataset, and 0·8935 for 5-year mortality and 0·9107 for 10-year mortality on the NHANES dataset. The individualised explanations that revealed the contribution of specific characteristics to ENABL Age provided insights into the important characteristics for ageing. An association analysis with risk factors and ageing-related morbidities and GWAS results on ENABL Age clocks trained on different mortality causes showed that each clock captures distinct ageing mechanisms.
Interpretation
ENABL Age brings an important leap forward in the application of XAI for interpreting biological age clocks. ENABL Age also carries substantial potential in practical settings, assisting medical professionals in untangling the complexity of ageing mechanisms, and potentially becoming a valuable tool in informed clinical decision-making processes.}},
  html={https://www.thelancet.com/journals/lanhl/article/PIIS2666-7568(23)00189-7/fulltext},
  pdf={https://www.thelancet.com/action/showPdf?pii=S2666-7568%2823%2900189-7},
  selected={true},
}

@inproceedings{beebe2023explanation,
  abbr={IMLH},
  title={Explanation-guided dynamic feature selection for medical risk prediction},
  author={Beebe-Wang, Nicasia and Qiu, Wei and Lee, Su-In},
  booktitle={ICML 3rd Workshop on Interpretable Machine Learning in Healthcare (IMLH)},
  year={2023},
  abstract={{In medical risk prediction scenarios, machine learning methods have demonstrated an ability to learn complex and predictive relationships among rich feature sets. However, in practice, when faced with new patients, we may not have access all information expected by a trained risk model. We propose a framework to simultaneously provide flexible risk estimates for samples with missing features, as well as context-dependent feature recommendations to identify what piece of information may be most valuable to collect next. Our approach uses a fixed prediction model, a local feature explainer, and ensembles of imputed samples to generate risk prediction intervals and feature recommendations. Applied to a myocardial infarction risk prediction task in the UK Biobank dataset, we find that our approach can more efficiently predict risk of a heart attack with fewer observed features than traditional fixed imputation and global feature selection methods.}},
  html={https://openreview.net/forum?id=1itfhff53V#all},
  pdf={https://openreview.net/pdf?id=1itfhff53V},
  selected={true}
}

@inproceedings{guo2021automated,
  abbr={AAAI},
  title={Automated lay language summarization of biomedical scientific reviews},
  author={Guo*, Yue and Qiu*, Wei and Wang, Yizhong and Cohen, Trevor},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={1},
  pages={160--168},
  year={2021},
  abstract={{Health literacy has emerged as a crucial factor in making appropriate health decisions and ensuring treatment outcomes. However, medical jargon and the complex structure of professional language in this domain make health information especially hard to interpret. Thus, there is an urgent unmet need for automated methods to enhance the accessibility of the biomedical literature to the general population. This problem can be framed as a type of translation problem between the language of healthcare professionals, and that of the general public. In this paper, we introduce the novel task of automated generation of lay language summaries of biomedical scientific reviews, and construct a dataset to support the development and evaluation of automated methods through which to enhance the accessibility of the biomedical literature. We conduct analyses of the various challenges in performing this task, including not only summarization of the key points but also explanation of background knowledge and simplification of professional language. We experiment with state-of-the-art summarization models as well as several data augmentation techniques, and evaluate their performance using both automated metrics and human assessment. Results indicate that automatically generated summaries produced using contemporary neural architectures can achieve promising quality and readability as compared with reference summaries developed for the lay public by experts (best ROUGE-L of 50.24 and Flesch-Kincaid readability score of 13.30). We also discuss the limitations of the current effort, providing insights and directions for future work.}},
  html={https://ojs.aaai.org/index.php/AAAI/article/view/16089},
  pdf={https://ojs.aaai.org/index.php/AAAI/article/view/16089/15896},
  selected={false},
}

